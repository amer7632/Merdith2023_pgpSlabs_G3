{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts all the data for our analysis. The base two layers are the plate model (we use the one of M체ller et al. (2016), but any plate model could be used) and a set of raster grids of residual abyssal peridotite (RAP) (Merdith et al. 2019). For our anlaysis we limit our time of interest to just the past 5 Ma, but, again, anytime could be used (provided it has a plate model). There are obvious some considerations when applying it further back in time. The general method we have employed to trace the subduction of a slab is after McGirr et al. (2020), however one important difference we make is that we subduct individual 'points', while in McGirr et al. (2022) they connect each point into a subduction isochron.\n",
    "\n",
    "There are two methods to trace depth, the first one (or default one) is using the approach of McGirr et al. and estimating dip (we use the method of Mather et al. in review, which employs an ensemble machine learning method to predict dip using various parameters such as convergence rate, age of seafloor, slab roll-back etc.). In the second approach we assume dip is 0째 (i.e. we explicitly assume that there is no change in depth) and 'subduct' the plate parallel to the Earths surface. We then use the distance-depth from trench data from Slab2 to attach a depth to our 'subducted' points (in this manner we are explicitly mapping points to the surface of Slab2*). With our depth estimates we can then link to the thermal properties of each subduction zone determined by Syracuse et al. (2010) by mapping nearest depth to nearest depth (this is done for both approaches). The output of this notebook contains results for both methods, and the results are broadly similar and become an esimate of uncertainty.\n",
    "\n",
    "Datasets used are:\n",
    "\n",
    "-Slab2 (Hayes et al. 2018)\n",
    "\n",
    "-Syracuse subduction zone thermal data (Syracuse et al. 2010)\n",
    "\n",
    "-Residual Abyssal Peridotite grids (Merdith et al. 2019; 2020) (+ other various grids such as age, spreading rate etc.))\n",
    "\n",
    "-Plate model (M체ller et al. 2016)\n",
    "\n",
    "*possibly need to check this, it uses GMT track so it matches that lat-lon of the 0째 dip subducted point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from gplately import pygplates\n",
    "from os import walk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygmt\n",
    "import slab_workflow\n",
    "import gplately\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rc('font', family='sans-serif') \n",
    "mpl.rc('font', serif='Helvetica Neue') \n",
    "mpl.rc('text', usetex='false') \n",
    "mpl.rcParams.update({'font.size': 8})\n",
    "#for some reason we get repetitive deprecation warnings, so this mutes them\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call GPlately's DataServer object and download the plate model\n",
    "rotation_model = pygplates.RotationModel('./data/plate_model/Global_EarthByte_230-0Ma_GK07_AREPS.rot')\n",
    "topology_features = ['./data/plate_model/Global_EarthByte_230-0Ma_GK07_AREPS_Topology_BuildingBlocks.gpml',\n",
    "                      './data/plate_model/Global_EarthByte_230-0Ma_GK07_AREPS_PlateBoundaries.gpml']\n",
    "static_polygons = pygplates.FeatureCollection('./data/plate_model/Global_EarthByte_230-0Ma_GK07_AREPS_Coastlines.gpml')\n",
    "\n",
    "# Use the PlateReconstruction object to create a plate motion model\n",
    "model = gplately.PlateReconstruction(rotation_model, topology_features, static_polygons)\n",
    "\n",
    "# Obtain geometry shapefiles with gdownload\n",
    "#coastlines, continents, COBs = gdownload.get_topology_geometries()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grids\n",
    "grid_filename = ['./data/grids/peridotite_thickness_post_serpentinisation_%s_Ma.nc',\n",
    "                 './data/grids//Muller_etal_2016_AREPS_v1.17_AgeGrid-%s.nc',\n",
    "                 './data/grids/rategrid_final_mask_%s.nc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(819, 818), (972, 911)]\n",
      "here (819, 972)\n",
      "[(564, 674)]\n",
      "here (564,)\n",
      "[(904, 802), (969, 901)]\n",
      "here (904, 969)\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "5\n",
      "times 5 -1 -1\n",
      "Using 5.00 to 4.00 Ma stage pole for plate 564\n",
      "Using 4.00 to 3.00 Ma stage pole for plate 904\n",
      "Using 5.00 to 4.00 Ma stage pole for plate 564\n",
      "Using 4.00 to 3.00 Ma stage pole for plate 904\n",
      "Using 5.00 to 4.00 Ma stage pole for plate 564\n",
      "Using 4.00 to 3.00 Ma stage pole for plate 904\n",
      "Using 5.00 to 4.00 Ma stage pole for plate 564\n",
      "Using 4.00 to 3.00 Ma stage pole for plate 904\n",
      "Using 5.00 to 4.00 Ma stage pole for plate 564\n",
      "4\n",
      "times 4 -1 -1\n",
      "Using 4.00 to 3.00 Ma stage pole for plate 904\n",
      "Using 4.00 to 3.00 Ma stage pole for plate 904\n",
      "Using 4.00 to 3.00 Ma stage pole for plate 904\n",
      "Using 4.00 to 3.00 Ma stage pole for plate 904\n",
      "3\n",
      "times 3 -1 -1\n",
      "2\n",
      "times 2 -1 -1\n",
      "1\n",
      "times 1 -1 -1\n",
      "0\n",
      "times 0 -1 -1\n"
     ]
    }
   ],
   "source": [
    "tessellation_threshold_radians = np.deg2rad(1)#np.deg2rad(0.1)\n",
    "output_data = slab_workflow.get_subducted_points(5,0,1,model, grid_filename, tessellation_threshold_radians=tessellation_threshold_radians)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#organise our results\n",
    "output_times = []\n",
    "output_points = []\n",
    "output_depths = []\n",
    "output_widths = []\n",
    "output_peridotite = []\n",
    "output_slab_age = []\n",
    "output_spread_rate = []\n",
    "output_dips = []\n",
    "output_conv_rate = []\n",
    "output_sub_ids = []\n",
    "output_no_dip_points = []\n",
    "output_distances = []\n",
    "for ind, output_at_time in enumerate(output_data[::-1]):\n",
    "    #output_at_time = np.asarray(output_at_time)\n",
    "    print(ind)\n",
    "    #print(i.shape)\n",
    "    tmp_output_times = np.asarray([output_at_time[0]]*len(output_at_time[1]))\n",
    "    output_times.append(tmp_output_times)\n",
    "    output_points.append(output_at_time[1])\n",
    "    output_depths.append(output_at_time[2])\n",
    "    output_peridotite.append(output_at_time[3][0])\n",
    "    output_slab_age.append(output_at_time[3][1])\n",
    "    output_spread_rate.append(output_at_time[3][2])\n",
    "    output_dips.append(output_at_time[4])\n",
    "    output_widths.append(output_at_time[5])\n",
    "    output_conv_rate.append(output_at_time[8])\n",
    "    output_sub_ids.append(output_at_time[7])\n",
    "    output_no_dip_points.append(output_at_time[9])\n",
    "    output_distances.append(output_at_time[10])\n",
    "    \n",
    "output_times = np.asarray(output_times, dtype=object)\n",
    "output_points = np.asarray(output_points, dtype=object)\n",
    "output_depths = np.asarray(output_depths, dtype=object)\n",
    "output_peridotite = np.asarray(output_peridotite, dtype=object)\n",
    "output_slab_age = np.asarray(output_slab_age, dtype=object)\n",
    "output_spread_rate = np.asarray(output_spread_rate, dtype=object)\n",
    "output_dips = np.asarray(output_dips, dtype=object)\n",
    "output_widths = np.asarray(output_widths, dtype=object)\n",
    "output_conv_rate = np.asarray(output_conv_rate, dtype=object )\n",
    "output_sub_ids = np.asarray(output_sub_ids, dtype=object )\n",
    "output_no_dip_points = np.asarray(output_no_dip_points, dtype=object )\n",
    "output_distances = np.asarray(output_distances, dtype=object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take output data and make it flat-\n",
    "all_sub_times_flat = []\n",
    "all_points_flat = []\n",
    "all_depths_flat = []\n",
    "all_peridotite_flat = []\n",
    "all_slab_age_flat = []\n",
    "all_spread_rate_flat = []\n",
    "all_dips_flat = []\n",
    "all_widths_flat = []\n",
    "all_conv_rate_flat = []\n",
    "all_sub_ids_flat = []\n",
    "all_no_dip_points_flat = []\n",
    "all_distances_flat = []\n",
    "\n",
    "for ind, output_point in enumerate(output_points):\n",
    "    for ind2, point in enumerate(output_point):\n",
    "        all_sub_times_flat.append(output_times[ind][ind2])\n",
    "        all_points_flat.append((point.to_lat_lon()[1],\n",
    "                                point.to_lat_lon()[0]))\n",
    "        \n",
    "        all_depths_flat.append(output_depths[ind][ind2])        \n",
    "        all_peridotite_flat.append(output_peridotite[ind][ind2]/1000)#NBNBNB std is in m, mean is in km\n",
    "        all_slab_age_flat.append(output_slab_age[ind][ind2])\n",
    "        all_spread_rate_flat.append(output_spread_rate[ind][ind2])\n",
    "        all_dips_flat.append(output_dips[ind][ind2])\n",
    "        all_widths_flat.append(output_widths[ind][ind2])\n",
    "        all_conv_rate_flat.append(float(output_conv_rate[ind][ind2]))\n",
    "        all_sub_ids_flat.append(float(output_sub_ids[ind][ind2]))\n",
    "        all_no_dip_points_flat.append((output_no_dip_points[ind][ind2].to_lat_lon()[1],\n",
    "                                       output_no_dip_points[ind][ind2].to_lat_lon()[0]))\n",
    "        all_distances_flat.append(float(output_distances[ind][ind2]))\n",
    "        \n",
    "all_sub_times_flat = np.asarray(all_sub_times_flat)        \n",
    "all_points_flat = np.asarray(all_points_flat)        \n",
    "all_depths_flat = np.asarray(all_depths_flat)        \n",
    "all_peridotite_flat = np.asarray(all_peridotite_flat)\n",
    "#when doing STD some are negative\n",
    "all_peridotite_flat[all_peridotite_flat < 0] = 0.01\n",
    "all_slab_age_flat = np.asarray(all_slab_age_flat)\n",
    "all_spread_rate_flat = np.asarray(all_spread_rate_flat)\n",
    "all_dips_flat = np.asarray(all_dips_flat)        \n",
    "all_widths_flat = np.asarray(all_widths_flat)        \n",
    "all_conv_rate_flat = np.asarray(all_conv_rate_flat)\n",
    "all_sub_ids_flat = np.asarray(all_sub_ids_flat)     \n",
    "all_no_dip_points_flat = np.asarray(all_no_dip_points_flat)     \n",
    "all_distances_flat = np.asarray(all_distances_flat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick plot to make sure everything is looking okay\n",
    "proj = ccrs.Mollweide(central_longitude=180)\n",
    "extent_globe = [-180,180,-90,90]\n",
    "\n",
    "fig = plt.figure(figsize=(24,16))\n",
    "ax = plt.axes(projection=proj)\n",
    "ax.set_global()\n",
    "sc = ax.scatter(all_points_flat[:,0],\n",
    "                all_points_flat[:,1], c=all_dips_flat, transform=ccrs.PlateCarree() )\n",
    "\n",
    "#ax.scatter(track_dep.iloc[:,0].values,\n",
    "#           track_dep.iloc[:,1].values, c=track_dep.iloc[:,2].values, transform=ccrs.PlateCarree())\n",
    "\n",
    "#im = ax.imshow(ds_dep['z'], extent=extent_globe, origin='lower', transform=ccrs.PlateCarree(),cmap='inferno')\n",
    "ax.coastlines()\n",
    "fig.colorbar(sc, orientation='horizontal', shrink=0.5, label='dip angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick plot to make sure everything is looking okay\n",
    "proj = ccrs.Mollweide(central_longitude=180)\n",
    "extent_globe = [-180,180,-90,90]\n",
    "\n",
    "fig = plt.figure(figsize=(24,16))\n",
    "ax = plt.axes(projection=proj)\n",
    "ax.set_global()\n",
    "sc = ax.scatter(all_points_flat[:,0],\n",
    "                all_points_flat[:,1], c=all_dips_flat, transform=ccrs.PlateCarree() )\n",
    "\n",
    "#ax.scatter(track_dep.iloc[:,0].values,\n",
    "#           track_dep.iloc[:,1].values, c=track_dep.iloc[:,2].values, transform=ccrs.PlateCarree())\n",
    "\n",
    "#im = ax.imshow(ds_dep['z'], extent=extent_globe, origin='lower', transform=ccrs.PlateCarree(),cmap='inferno')\n",
    "ax.coastlines()\n",
    "fig.colorbar(sc, orientation='horizontal', shrink=0.5, label='dip angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.Mollweide(central_longitude=180)\n",
    "extent_globe = [-180,180,-90,90]\n",
    "\n",
    "fig = plt.figure(figsize=(24,16))\n",
    "ax = plt.axes(projection=proj)\n",
    "ax.set_global()\n",
    "sc = ax.scatter(all_points_flat[:,0],\n",
    "                all_points_flat[:,1], c=all_conv_rate_flat, s=5, transform=ccrs.PlateCarree() )\n",
    "\n",
    "#ax.scatter(track_dep.iloc[:,0].values,\n",
    "#           track_dep.iloc[:,1].values, c=track_dep.iloc[:,2].values, transform=ccrs.PlateCarree())\n",
    "\n",
    "#im = ax.imshow(ds_dep['z'], extent=extent_globe, origin='lower', transform=ccrs.PlateCarree(),cmap='inferno')\n",
    "ax.coastlines()\n",
    "fig.colorbar(sc, orientation='horizontal', shrink=0.5, label='conv velocity (km/Ma)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.Mollweide(central_longitude=180)\n",
    "extent_globe = [-180,180,-90,90]\n",
    "\n",
    "fig = plt.figure(figsize=(24,16))\n",
    "ax = plt.axes(projection=proj)\n",
    "ax.set_global()\n",
    "sc = ax.scatter(all_points_flat[:,0],\n",
    "                all_points_flat[:,1], c=all_conv_rate_flat, transform=ccrs.PlateCarree() )\n",
    "\n",
    "#ax.scatter(track_dep.iloc[:,0].values,\n",
    "#           track_dep.iloc[:,1].values, c=track_dep.iloc[:,2].values, transform=ccrs.PlateCarree())\n",
    "\n",
    "#im = ax.imshow(ds_dep['z'], extent=extent_globe, origin='lower', transform=ccrs.PlateCarree(),cmap='inferno')\n",
    "ax.coastlines()\n",
    "fig.colorbar(sc, orientation='horizontal', shrink=0.5, label='conv velocity (km/Ma)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get slab2 data\n",
    "ds_dep = xr.open_dataset('./data/Slab2_compiled_dep.nc')\n",
    "ds_dip = xr.open_dataset('./data/Slab2_compiled_dip.nc')\n",
    "ds_unc = xr.open_dataset('./data/Slab2_compiled_unc.nc')\n",
    "\n",
    "#get points from Slab2 ASSUMING no dip \n",
    "track_dep = pygmt.grdtrack(points=all_no_dip_points_flat, grid=ds_dep['z'], newcolname='dep')#, Verbose=False)\n",
    "track_dip = pygmt.grdtrack(points=all_no_dip_points_flat, grid=ds_dip['z'], newcolname='dip')#, Verbose=False)\n",
    "track_unc = pygmt.grdtrack(points=all_no_dip_points_flat, grid=ds_unc['z'], newcolname='unc')#, Verbose=False)\n",
    "\n",
    "\n",
    "#our data so far is in - km, lets convert to (positive) km\n",
    "track_dep.iloc[:,2] = track_dep.iloc[:,2]*-1\n",
    "track_unc.iloc[:,2] = track_unc.iloc[:,2]*-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate P&T data from Syracuse et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10,
     16,
     22
    ]
   },
   "outputs": [],
   "source": [
    "# Options for Model are:\n",
    "#  - D80\n",
    "#  - X25\n",
    "#  - W1300\n",
    "#  - T550\n",
    "MODEL = 'T550'\n",
    "datadir = '/Users/andrew/Documents/Data/Merdith_sub_zones/'\n",
    "SlabDir = '%ssyracuse_thermal/Syracuse++_supp_Material/models/%s' % (datadir, MODEL)\n",
    "\n",
    "files=[]\n",
    "for(dirpath,dirnames,filenames) in walk(SlabDir):\n",
    "    files.extend(filenames)\n",
    "    break\n",
    "files.sort()\n",
    "#print f\n",
    "arcs = []\n",
    "for file in files:\n",
    "    arcs.append(file.split('.')[0])\n",
    "    \n",
    "#slab surface | moho surface | slab curie depth | magnetite depth | moho curie depth\n",
    "surface_arrays = []\n",
    "isotherm_arrays = []\n",
    "for j in np.arange(len(files)):\n",
    "\n",
    "        FNAME = files[j]\n",
    "\n",
    "        tmp_surface_arrays, tmp_isotherm_arrays = slab_workflow.get_slab_surfaces(SlabDir, FNAME)\n",
    "        surface_arrays.append(tmp_surface_arrays)\n",
    "        isotherm_arrays.append(tmp_isotherm_arrays)\n",
    "        \n",
    "#NB results are:\n",
    "#surface (0 for top of slab, 7 for moho) | horiontal distance from trench | depth | temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find nearest subduction zone of SYR10 to each point in our analysis\n",
    "#load csv data of syracuse\n",
    "closest_indices = []\n",
    "closest_sub = []\n",
    "thermal_data = []\n",
    "\n",
    "df_syracuse = pd.read_csv('%ssyracuse_thermal/Table_2_sub_parameters.csv' % datadir)\n",
    "input_lat = all_points_flat[0][1]\n",
    "input_lon = all_points_flat[0][0]\n",
    "indices = []\n",
    "for point_index, point in enumerate(all_points_flat[:]):\n",
    "    #print(point_index)\n",
    "    input_lon = point[0]\n",
    "    input_lat = point[1]\n",
    "    #sort by lat and lon to get a 'top 10'\n",
    "    df_sort = df_syracuse.iloc[(df_syracuse['Lat']-int(input_lat)).abs().argsort()[:10]]\n",
    "    df_close = df_sort.iloc[(df_sort['Lon']-int(input_lon)).abs().argsort()[:10]]\n",
    "    #to find actual closest we will caclulate the distance between the input lat/lon and the 'top 10'\n",
    "    distance_to_syracuse = []\n",
    "    for tmp_lat ,tmp_lon in zip(df_close['Lat'], df_close['Lon']):\n",
    "        distance_to_syracuse.append(pygplates.GeometryOnSphere.distance(pygplates.PointOnSphere(input_lat,\n",
    "                                                                                                input_lon),\n",
    "                                                                        pygplates.PointOnSphere(tmp_lat,\n",
    "                                                                                                tmp_lon)\n",
    "                                                                        )\n",
    "                                   )\n",
    "        \n",
    "    min_index = distance_to_syracuse.index(min(distance_to_syracuse))# Find the index of the minimum value.\n",
    "    df_closest = df_close.iloc[[min_index]]\n",
    "    closest_index = df_closest.index.tolist()\n",
    "    #\n",
    "    ###index of closest will correspond to our slab surface database index\n",
    "    index_of_closest = slab_workflow.find_with_list(arcs, df_closest['Name'].values[0])\n",
    "    thermal_data_of_closest = surface_arrays[index_of_closest[0]]\n",
    "    closest_indices.append(closest_index[0])\n",
    "    closest_sub.append(df_closest['Name'].values[0])\n",
    "    thermal_data.append(thermal_data_of_closest)\n",
    "    indices.append(point_index)\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure = ((upper_crust_thickness * rho_upper_crust) +\n",
    "                (lower_crust_thickness * rho_lower_crust) +\n",
    "                (upper_mantle_thickness * rho_upper_mantle)) * 9.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_pressure = []\n",
    "local_slab2_pressure = []\n",
    "local_model_temp = []\n",
    "local_slab2_temp = []\n",
    "for point_index, point in enumerate(all_points_flat[:]):\n",
    "    #print(point_index)\n",
    "    model_point_depth = all_depths_flat[point_index]\n",
    "    slab2_point_depth = track_dep.iloc[point_index,2]\n",
    "    local_model_pressure.append(slab_workflow.calc_point_pressure(model_point_depth))\n",
    "    local_slab2_pressure.append(slab_workflow.calc_point_pressure(slab2_point_depth))\n",
    "    ##now for thermal data, [1] for slab moho, [0] for slab surface\n",
    "    syracuse_depths = thermal_data[point_index][1][::,2]\n",
    "    syracuse_temps = thermal_data[point_index][1][::,3]\n",
    "\n",
    "    ###get nearest indices (of our depth to syrcause depth)\n",
    "    vec_nearest_SYR = lambda x: slab_workflow._find_nearest_temp(syracuse_depths, x)\n",
    "    index_of_nearest_model_depth_SYR = np.abs(syracuse_depths-model_point_depth).argmin()\n",
    "    index_of_nearest_slab2_depth_SYR = np.abs(syracuse_depths-slab2_point_depth).argmin()\n",
    "    temp_at_model_depth = syracuse_temps[index_of_nearest_model_depth_SYR]\n",
    "    temp_at_slab2_depth = syracuse_temps[index_of_nearest_slab2_depth_SYR]\n",
    "    \n",
    "    local_model_temp.append(temp_at_model_depth)\n",
    "    local_slab2_temp.append(temp_at_slab2_depth)\n",
    "    \n",
    "local_model_pressure = np.asarray(local_model_pressure)\n",
    "local_slab2_pressure = np.asarray(local_slab2_pressure)\n",
    "local_model_temp = np.asarray(local_model_temp)\n",
    "local_slab2_temp = np.asarray(local_slab2_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get peridotite volume, crustal volume flux and fraction content of crust\n",
    "volume_perids = all_peridotite_flat*all_widths_flat*1e-3*all_conv_rate_flat\n",
    "crust_flux = 7*all_widths_flat*1e-3*all_conv_rate_flat #assume 7 km of crust?\n",
    "fractional_perid = perids_fraction = np.divide(volume_perids, \n",
    "                                               crust_flux,\n",
    "                                               out=np.zeros_like(volume_perids),\n",
    "                                               where=crust_flux!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'point_sub_times': all_sub_times_flat,\n",
    "             'point_lats': all_points_flat[:,0],\n",
    "             'point_lons': all_points_flat[:,1],\n",
    "             'point_MODEL_depths': all_depths_flat,\n",
    "             'point_MODEL_no_DIP_lats': all_no_dip_points_flat[:,0],\n",
    "             'point_MODEL_no_DIP_lons': all_no_dip_points_flat[:,1],\n",
    "             'point_MODEL_no_DIP_distances': all_distances_flat,\n",
    "             'point_SLAB2_depths': track_dep.iloc[:,2],\n",
    "             'point_SLAB2_uncertainty': track_unc.iloc[:,2],\n",
    "             'point_widths': all_widths_flat*1e-3,#conver from m to km\n",
    "             'point_conv_rates': all_conv_rate_flat,\n",
    "             'point_perids': all_peridotite_flat,\n",
    "             'volume_perids': volume_perids,\n",
    "             'fractional_perids':fractional_perid,\n",
    "             'crust_flux': crust_flux,\n",
    "             'point_slab_ages': all_slab_age_flat,\n",
    "             'point_spread_rates': all_spread_rate_flat,\n",
    "             'point_sub_ids': all_sub_ids_flat,\n",
    "             'point_MODEL_dips': all_dips_flat,\n",
    "             'point_SLAB2_dips': track_dip.iloc[:,2],\n",
    "             'sub_zone_SYR10': closest_sub,\n",
    "             'pressure_MODEL': local_model_pressure,\n",
    "             'pressure_SLAB2': local_slab2_pressure,\n",
    "             'temp_SYR10_MODEL': local_model_temp,\n",
    "             'temp_SYR10_SLAB2': local_slab2_temp\n",
    "            }\n",
    "\n",
    "tracks = pd.DataFrame.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#save as pickle\n",
    "#with open('./subduction_tracks_2022-11-02_STD.pickle', 'wb') as f:\n",
    "    #pickle.dump(tracks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyH2slabs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b25a8f875d76226d1acd84537a0c1d156992936d128734f43e2d3ed1c73c844a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
